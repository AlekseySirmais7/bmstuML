{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Лабораторная работа 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задачи:\n",
    "\n",
    "* Провести классификацию русских текстов на несколько категорий. Лучше большой текст\n",
    "* Провести предобработку текстов: нормализацию, лемматизацию и тд\n",
    "* Сравнить эмбеддинги\n",
    "* Попробовать несколько методов классификации (+косинусы)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Будем использовать Войну и мир, Краткую историю всего"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# будем делить Войду и мир, Краткую историю всего на partsCount одинаковых частей\n",
    "partsCount = 30\n",
    "myTestSize = 0.2\n",
    "\n",
    "textDir = \"/home/alex/Downloads/bmstuML/texts/\"\n",
    "\n",
    "warFile = textDir + \"voina_i_mir.txt\"\n",
    "\n",
    "istoriaFile = textDir + \"kratkaya.txt\"\n",
    "\n",
    "\n",
    "with open(warFile, encoding=\"utf8\") as f:\n",
    "    war_text = f.read()\n",
    "    \n",
    "with open(istoriaFile, encoding=\"utf8\") as f:\n",
    "    istoria_text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nЛев Толстой\\n\\nВойна и мир\\n\\nТома первый и второй\\n\\n\\n\\nВ.\\xa0Шкловский «Война и мир» Льва Толстого\\n\\n\\nЗамысел\\n\\nВ 1855 году появилось объявление об издании «Полярной звезды». На обложке книги в круге восходящего солнца были изображены пять портретов казненных декабристов; под портретами топор и подписано: «'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "war_text[:300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n«Краткая история почти всего на свете» Билла Брайсона — самая необычная энциклопедия из всех существующих! И это первая книга, которой была присуждена престижная европейская премия за вклад в развитие мировой науки имени Рене Декарта.\\n\\n\\n\\nСейчас, в начале 2003 года, я держу перед собой несколько стр'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "istoria_text[:300]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Токенизация\n",
    "\n",
    "Выделим из текстов отдельные слова. Удалим ненужные \"слова\" (знаки препинания, лишние символы)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/alex/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Лев',\n",
       " 'Толстой',\n",
       " 'Война',\n",
       " 'и',\n",
       " 'мир',\n",
       " 'Тома',\n",
       " 'первый',\n",
       " 'и',\n",
       " 'второй',\n",
       " 'В.',\n",
       " 'Шкловский',\n",
       " '«',\n",
       " 'Война',\n",
       " 'и',\n",
       " 'мир']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "nltk.download(\"punkt\")\n",
    "war_tokens = nltk.word_tokenize(war_text)\n",
    "\n",
    "war_tokens[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['«',\n",
       " 'Краткая',\n",
       " 'история',\n",
       " 'почти',\n",
       " 'всего',\n",
       " 'на',\n",
       " 'свете',\n",
       " '»',\n",
       " 'Билла',\n",
       " 'Брайсона',\n",
       " '—',\n",
       " 'самая',\n",
       " 'необычная',\n",
       " 'энциклопедия',\n",
       " 'из']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# второй текст\n",
    "istoria_tokens = nltk.word_tokenize(istoria_text)\n",
    "\n",
    "istoria_tokens[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['лев', 'толст', 'войн', 'и', 'мир', 'том', 'перв', 'и', 'втор', 'в.']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from snowballstemmer import RussianStemmer\n",
    "stemmer = RussianStemmer()\n",
    "stemmerResult = stemmer.stemWords(war_text.lower().split())\n",
    "\n",
    "stemmerResult[:10]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видим, слова получились \"кривыми\", простое обрезание окончания - не вариант. Воспользуемся лемматизатором."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymystem3\n",
    "\n",
    "mystem = pymystem3.Mystem()\n",
    "\n",
    "war_lemm = mystem.lemmatize(\" \".join(war_tokens))\n",
    "\n",
    "istoria_lemm = mystem.lemmatize(\" \".join(istoria_tokens))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['лев',\n",
       " ' ',\n",
       " 'толстой',\n",
       " ' ',\n",
       " 'война',\n",
       " ' ',\n",
       " 'и',\n",
       " ' ',\n",
       " 'мир',\n",
       " ' ',\n",
       " 'том',\n",
       " ' ',\n",
       " 'первый',\n",
       " ' ',\n",
       " 'и',\n",
       " ' ',\n",
       " 'второй',\n",
       " ' ',\n",
       " 'в',\n",
       " '. ']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "war_lemm[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['« ',\n",
       " 'краткий',\n",
       " ' ',\n",
       " 'история',\n",
       " ' ',\n",
       " 'почти',\n",
       " ' ',\n",
       " 'все',\n",
       " ' ',\n",
       " 'на',\n",
       " ' ',\n",
       " 'свет',\n",
       " ' » ',\n",
       " 'билл',\n",
       " ' ',\n",
       " 'брайсон',\n",
       " ' — ',\n",
       " 'самый',\n",
       " ' ',\n",
       " 'необычный']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "istoria_lemm[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на морфологический анализ слов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parse(word='свет', tag=OpencorporaTag('NOUN,inan,masc,Sgtm sing,nomn'), normal_form='свет', score=0.51923, methods_stack=((DictionaryAnalyzer(), 'свет', 557, 0),)),\n",
       " Parse(word='свет', tag=OpencorporaTag('NOUN,inan,masc,Sgtm sing,accs'), normal_form='свет', score=0.423076, methods_stack=((DictionaryAnalyzer(), 'свет', 557, 4),)),\n",
       " Parse(word='свет', tag=OpencorporaTag('NOUN,anim,femn,Name plur,gent'), normal_form='света', score=0.01923, methods_stack=((DictionaryAnalyzer(), 'свет', 237, 8),)),\n",
       " Parse(word='свет', tag=OpencorporaTag('NOUN,anim,femn,Name plur,accs'), normal_form='света', score=0.01923, methods_stack=((DictionaryAnalyzer(), 'свет', 237, 10),)),\n",
       " Parse(word='свет', tag=OpencorporaTag('NOUN,anim,femn,Name sing,voct,Infr'), normal_form='света', score=0.01923, methods_stack=((DictionaryAnalyzer(), 'свет', 237, 13),))]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pymorphy2\n",
    "morph = pymorphy2.MorphAnalyzer()\n",
    "morph.parse(\"свет\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Удалим знаки пустые слова\n",
    "\n",
    "bad_chars = [\"«\", \"»\",\".\",\",\",\"—\",\":\",\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\",\"0\",\"?\",\"-\",\"[\",\"]\", \"стр\", \"(\", \")\",\n",
    "            \";\", \"X\", \"!\", \"издание\", \"…\", \"’\",\"&\"]\n",
    "\n",
    "def containsStr(a,b):\n",
    "    for i in b:\n",
    "        if i in a:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def deleteWords(wordList):\n",
    "    resultList = [item for item in wordList if len(item) > 1 ]\n",
    "    resultList = [item for item in resultList if not containsStr(item, bad_chars) ]\n",
    "    return resultList\n",
    "\n",
    "\n",
    "\n",
    "war_lemm_clear = deleteWords(war_lemm)\n",
    "\n",
    "istoria_lemm_clear = deleteWords(istoria_lemm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['лев',\n",
       " 'толстой',\n",
       " 'война',\n",
       " 'мир',\n",
       " 'том',\n",
       " 'первый',\n",
       " 'второй',\n",
       " 'шкловский',\n",
       " 'война',\n",
       " 'мир',\n",
       " 'лев',\n",
       " 'толстой',\n",
       " 'замысел',\n",
       " 'год',\n",
       " 'появляться',\n",
       " 'объявление',\n",
       " 'об',\n",
       " 'полярный',\n",
       " 'звезда',\n",
       " 'на']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "war_lemm_clear[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['краткий',\n",
       " 'история',\n",
       " 'почти',\n",
       " 'все',\n",
       " 'на',\n",
       " 'свет',\n",
       " 'билл',\n",
       " 'брайсон',\n",
       " 'самый',\n",
       " 'необычный',\n",
       " 'энциклопедия',\n",
       " 'из',\n",
       " 'весь',\n",
       " 'существующий',\n",
       " 'это',\n",
       " 'первый',\n",
       " 'книга',\n",
       " 'который',\n",
       " 'быть',\n",
       " 'присуждать']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "istoria_lemm_clear[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "war_text_clear = \" \".join(war_lemm_clear)\n",
    "istoria_text_clear = \" \".join(istoria_lemm_clear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'лев толстой война мир том первый второй шкловский война мир лев толстой замысел год появляться объявление об полярный звезда на обложка книга круг восходить солнце быть изображать пять портрет казнить декабрист под портрет топор подписывать июль год том помечать день казнь декабрист над заглавие туч'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "war_text_clear[:300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# сохраним текста\n",
    "\n",
    "# with open(textDir+ '1.txt', 'w') as file:\n",
    "#     file.write(war_text_clear)\n",
    "    \n",
    "# with open(textDir+ '2.txt', 'w') as file:\n",
    "#     file.write(istoria_text_clear)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# функция разделения на части\n",
    "def chunkify(lst,n):\n",
    "    return [lst[i::n] for i in range(n)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['краткий',\n",
       " 'декарт',\n",
       " 'изобретательность',\n",
       " 'относиться',\n",
       " 'мало',\n",
       " 'повторяться',\n",
       " 'из',\n",
       " 'иан',\n",
       " 'хичкок',\n",
       " 'оффенбур']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "war_parts = chunkify(war_lemm_clear, partsCount)\n",
    "istoria_parts = chunkify(istoria_lemm_clear, partsCount)\n",
    "\n",
    "istoria_parts[0][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# объединяем \n",
    "def joinWordsToTextList(wordsLists):\n",
    "    result = []\n",
    "    for i in wordsLists:\n",
    "        oneText = \" \".join(i)\n",
    "        result.append(oneText)\n",
    "    return result\n",
    "\n",
    "\n",
    "war_texts = joinWordsToTextList(war_parts)\n",
    "istoria_texts = joinWordsToTextList(istoria_parts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'толстой под изранить писать собр робкий ежели мой мыльный не пародировать государство год один на трещать характеристика герой что аракчеев путь три николай класс это воспоминание произведение среди близкий эпоха как объяснять обозначать семья иван часть вследствие толстой думать крайний только рома'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "war_texts[1][:300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "war_texts size:46816 \tistoria_text size:34467\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(columns=[\"text\",\"class\"])\n",
    "\n",
    "\n",
    "for i in war_texts:\n",
    "    df = df.append(pd.Series({\"text\":i, \"class\":0}), ignore_index=True)\n",
    "\n",
    "for i in istoria_texts:\n",
    "    df = df.append(pd.Series({\"text\":i, \"class\":1}), ignore_index=True)\n",
    "    \n",
    "\n",
    "print(\"war_texts size:\"+str(len(war_texts[3])), \"\\tistoria_text size:\"+str(len(istoria_texts[3])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>лев декабрист солдат толстой полна человек рыл...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>толстой под изранить писать собр робкий ежели ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>война портрет твердый из соч не мыльный россия...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>мир топор как брюссель дальнейший мочь пузырь ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>том подписывать гранит герцен ссылка понимать ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>первый июль испытывать что на что лопнуть ясны...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>второй год свой он этот лед для как попадать б...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>шкловский том сила теперь приводиться трещать ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>война помечать так только непосредственно руши...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>мир день же прочитывать текст под то рылеев ми...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>лев казнь подставлять шестой указание нога это...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>толстой декабрист свой книга том этот тоже быт...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>замысел над спина полярный крах самый доказате...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>год заглавие палка звезда николаевский доказыв...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>появляться туча как восторг россия что мы чело...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>объявление звезда прежде превосходный быть чел...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>об полярный герцен весь очевидный идти надуват...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>полярный объявление собр этот для что новый жи...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>звезда быть соч книга все один пузырь без геро...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>на целый ти это толстой средство который это к...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>обложка манифест том не писать не еще письмо д...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>книга герцен год мой герцен проваливаться сам ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>круг говорить толстой один сомневаться это не ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>восходить восстание совершать мнение человек и...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>солнце декабрист заграничный но говорить не эт...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>быть севастопольский поездка все новый останав...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>изображать кампания познакомиться кто сила тол...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>пять спрашивать герцен только человек вспомина...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>портрет неужели год видеть робкий письмо тверд...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>казнить севастопольский март толстой этот имя ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>краткий декарт изобретательность относиться ма...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>история сейчас мой сфера не простой музей татт...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>почти начало решение его мочь вопрос естествен...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>все год не интерес приступать просить история ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>на держать принимать первобытный повествование...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>свет перед выделять человек не но рафф естеств...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>билл себя курсив кто поблагодарить не из истор...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>брайсон несколько классификационный знать долж...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>самый доброжелательный подразделение сколько о...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>необычный тактичный высокий еще тот вы лондон ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>энциклопедия замечание уровень авторский кто э...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>из иан род ляп помогать еще хардинг дэвид есте...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>весь таттерсолл вид выплывать написать раз из ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>существующий из что на этот англия институт из...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>это американский упорно этот книга на биологич...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>первый музей искажать но особенно мой антропол...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>книга естественный написание благодаря обязыва...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>который история олоргезайль частность то отвеч...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>быть он место доктор кто дэвид лоренс нью из г...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>присуждать среди где таттерсолла неизменный кэ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>престижный прочее побывать все великодушие из ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>европейский отмечать совсем кто любезность имп...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>премия что недавно собираться проявлять коллед...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>за перига далее здесь поистине лондон уэллком ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>вклад не тот отмечать героический ричард кит б...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>развитие винодельческий же они терпение форти ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>мировой район дух быть отвечать лен из из орча...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>наука что касательно на на эллис таймс медицин...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>имя несмотря два много один кейти соединенный ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>рене на глава сотня бесконечно уэй штат дартму...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text class\n",
       "0   лев декабрист солдат толстой полна человек рыл...     0\n",
       "1   толстой под изранить писать собр робкий ежели ...     0\n",
       "2   война портрет твердый из соч не мыльный россия...     0\n",
       "3   мир топор как брюссель дальнейший мочь пузырь ...     0\n",
       "4   том подписывать гранит герцен ссылка понимать ...     0\n",
       "5   первый июль испытывать что на что лопнуть ясны...     0\n",
       "6   второй год свой он этот лед для как попадать б...     0\n",
       "7   шкловский том сила теперь приводиться трещать ...     0\n",
       "8   война помечать так только непосредственно руши...     0\n",
       "9   мир день же прочитывать текст под то рылеев ми...     0\n",
       "10  лев казнь подставлять шестой указание нога это...     0\n",
       "11  толстой декабрист свой книга том этот тоже быт...     0\n",
       "12  замысел над спина полярный крах самый доказате...     0\n",
       "13  год заглавие палка звезда николаевский доказыв...     0\n",
       "14  появляться туча как восторг россия что мы чело...     0\n",
       "15  объявление звезда прежде превосходный быть чел...     0\n",
       "16  об полярный герцен весь очевидный идти надуват...     0\n",
       "17  полярный объявление собр этот для что новый жи...     0\n",
       "18  звезда быть соч книга все один пузырь без геро...     0\n",
       "19  на целый ти это толстой средство который это к...     0\n",
       "20  обложка манифест том не писать не еще письмо д...     0\n",
       "21  книга герцен год мой герцен проваливаться сам ...     0\n",
       "22  круг говорить толстой один сомневаться это не ...     0\n",
       "23  восходить восстание совершать мнение человек и...     0\n",
       "24  солнце декабрист заграничный но говорить не эт...     0\n",
       "25  быть севастопольский поездка все новый останав...     0\n",
       "26  изображать кампания познакомиться кто сила тол...     0\n",
       "27  пять спрашивать герцен только человек вспомина...     0\n",
       "28  портрет неужели год видеть робкий письмо тверд...     0\n",
       "29  казнить севастопольский март толстой этот имя ...     0\n",
       "30  краткий декарт изобретательность относиться ма...     1\n",
       "31  история сейчас мой сфера не простой музей татт...     1\n",
       "32  почти начало решение его мочь вопрос естествен...     1\n",
       "33  все год не интерес приступать просить история ...     1\n",
       "34  на держать принимать первобытный повествование...     1\n",
       "35  свет перед выделять человек не но рафф естеств...     1\n",
       "36  билл себя курсив кто поблагодарить не из истор...     1\n",
       "37  брайсон несколько классификационный знать долж...     1\n",
       "38  самый доброжелательный подразделение сколько о...     1\n",
       "39  необычный тактичный высокий еще тот вы лондон ...     1\n",
       "40  энциклопедия замечание уровень авторский кто э...     1\n",
       "41  из иан род ляп помогать еще хардинг дэвид есте...     1\n",
       "42  весь таттерсолл вид выплывать написать раз из ...     1\n",
       "43  существующий из что на этот англия институт из...     1\n",
       "44  это американский упорно этот книга на биологич...     1\n",
       "45  первый музей искажать но особенно мой антропол...     1\n",
       "46  книга естественный написание благодаря обязыва...     1\n",
       "47  который история олоргезайль частность то отвеч...     1\n",
       "48  быть он место доктор кто дэвид лоренс нью из г...     1\n",
       "49  присуждать среди где таттерсолла неизменный кэ...     1\n",
       "50  престижный прочее побывать все великодушие из ...     1\n",
       "51  европейский отмечать совсем кто любезность имп...     1\n",
       "52  премия что недавно собираться проявлять коллед...     1\n",
       "53  за перига далее здесь поистине лондон уэллком ...     1\n",
       "54  вклад не тот отмечать героический ричард кит б...     1\n",
       "55  развитие винодельческий же они терпение форти ...     1\n",
       "56  мировой район дух быть отвечать лен из из орча...     1\n",
       "57  наука что касательно на на эллис таймс медицин...     1\n",
       "58  имя несмотря два много один кейти соединенный ...     1\n",
       "59  рене на глава сотня бесконечно уэй штат дартму...     1"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# разбив на трейн и тест\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df[\"text\"], df[\"class\"], test_size=myTestSize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag-of-Words-эмбеддинг\n",
    "на всех данных обучние - чтоб все слова были учтены?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "bof_vect = CountVectorizer()\n",
    "bof_vect.fit(np.hstack([X_train, X_test]))\n",
    "bof_train = bof_vect.transform(X_train)\n",
    "bof_test = bof_vect.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 1, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [1, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 1, 0, 0]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# пространство признаков\n",
    "\n",
    "bof_train.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48, 23015)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bof_train.toarray().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF-Эмбеддинг"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vect = TfidfVectorizer()\n",
    "tfidf_vect.fit(np.hstack([X_train, X_test]))\n",
    "tfidf_train = tfidf_vect.transform(X_train)\n",
    "tfidf_test = tfidf_vect.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , ..., 0.00378749, 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.00731328, 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.00675776, 0.        ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_train.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48, 23015)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_train.toarray().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2vec-эмбеддинг\n",
    "Немного другой формат данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "X_train_w2v = X_train.apply(str.split)\n",
    "X_test_w2v = X_test.apply(str.split)\n",
    "w2v_vect = Word2Vec(np.hstack([X_train_w2v, X_test_w2v]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27    [пять, спрашивать, герцен, только, человек, вс...\n",
       "0     [лев, декабрист, солдат, толстой, полна, челов...\n",
       "20    [обложка, манифест, том, не, писать, не, еще, ...\n",
       "26    [изображать, кампания, познакомиться, кто, сил...\n",
       "54    [вклад, не, тот, отмечать, героический, ричард...\n",
       "7     [шкловский, том, сила, теперь, приводиться, тр...\n",
       "10    [лев, казнь, подставлять, шестой, указание, но...\n",
       "14    [появляться, туча, как, восторг, россия, что, ...\n",
       "57    [наука, что, касательно, на, на, эллис, таймс,...\n",
       "29    [казнить, севастопольский, март, толстой, этот...\n",
       "18    [звезда, быть, соч, книга, все, один, пузырь, ...\n",
       "13    [год, заглавие, палка, звезда, николаевский, д...\n",
       "51    [европейский, отмечать, совсем, кто, любезност...\n",
       "5     [первый, июль, испытывать, что, на, что, лопну...\n",
       "2     [война, портрет, твердый, из, соч, не, мыльный...\n",
       "53    [за, перига, далее, здесь, поистине, лондон, у...\n",
       "11    [толстой, декабрист, свой, книга, том, этот, т...\n",
       "15    [объявление, звезда, прежде, превосходный, быт...\n",
       "32    [почти, начало, решение, его, мочь, вопрос, ес...\n",
       "22    [круг, говорить, толстой, один, сомневаться, э...\n",
       "49    [присуждать, среди, где, таттерсолла, неизменн...\n",
       "52    [премия, что, недавно, собираться, проявлять, ...\n",
       "38    [самый, доброжелательный, подразделение, сколь...\n",
       "16    [об, полярный, герцен, весь, очевидный, идти, ...\n",
       "55    [развитие, винодельческий, же, они, терпение, ...\n",
       "48    [быть, он, место, доктор, кто, дэвид, лоренс, ...\n",
       "1     [толстой, под, изранить, писать, собр, робкий,...\n",
       "56    [мировой, район, дух, быть, отвечать, лен, из,...\n",
       "47    [который, история, олоргезайль, частность, то,...\n",
       "41    [из, иан, род, ляп, помогать, еще, хардинг, дэ...\n",
       "8     [война, помечать, так, только, непосредственно...\n",
       "43    [существующий, из, что, на, этот, англия, инст...\n",
       "44    [это, американский, упорно, этот, книга, на, б...\n",
       "6     [второй, год, свой, он, этот, лед, для, как, п...\n",
       "30    [краткий, декарт, изобретательность, относитьс...\n",
       "50    [престижный, прочее, побывать, все, великодуши...\n",
       "28    [портрет, неужели, год, видеть, робкий, письмо...\n",
       "31    [история, сейчас, мой, сфера, не, простой, муз...\n",
       "42    [весь, таттерсолл, вид, выплывать, написать, р...\n",
       "58    [имя, несмотря, два, много, один, кейти, соеди...\n",
       "21    [книга, герцен, год, мой, герцен, проваливатьс...\n",
       "36    [билл, себя, курсив, кто, поблагодарить, не, и...\n",
       "45    [первый, музей, искажать, но, особенно, мой, а...\n",
       "33    [все, год, не, интерес, приступать, просить, и...\n",
       "46    [книга, естественный, написание, благодаря, об...\n",
       "17    [полярный, объявление, собр, этот, для, что, н...\n",
       "23    [восходить, восстание, совершать, мнение, чело...\n",
       "37    [брайсон, несколько, классификационный, знать,...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_w2v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alex/.local/lib/python3.6/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('земля', 0.991139829158783),\n",
       " ('мы', 0.9608840346336365),\n",
       " ('если', 0.9538167119026184),\n",
       " ('до', 0.9258429408073425),\n",
       " ('вид', 0.9246758818626404),\n",
       " ('тысяча', 0.9080923795700073),\n",
       " ('время', 0.9060119390487671),\n",
       " ('по', 0.9048091173171997),\n",
       " ('более', 0.9048004150390625),\n",
       " ('самый', 0.9034135341644287)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_vect.most_similar(positive=\"год\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alex/.local/lib/python3.6/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('ты', -0.5450881123542786),\n",
       " ('наташа', -0.5452762246131897),\n",
       " ('сказать', -0.5637020468711853),\n",
       " ('пьер', -0.5810374617576599),\n",
       " ('андрей', -0.5817877054214478),\n",
       " ('душенька', -0.586664617061615),\n",
       " ('она', -0.5878745317459106),\n",
       " ('князь', -0.5882515907287598),\n",
       " ('год', -0.6122918128967285),\n",
       " ('княжна', -0.6275584697723389)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_vect.most_similar(negative=[\"текст\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alex/.local/lib/python3.6/site-packages/ipykernel_launcher.py:2: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.5507305 ,  0.67350453, -0.24934688,  0.4454552 ,  1.685914  ,\n",
       "        0.082981  , -0.24887723, -0.367418  ,  0.36407822,  0.6357176 ,\n",
       "       -0.31058827, -0.56780154,  0.2013186 ,  0.73100334,  0.68598926,\n",
       "       -0.6844782 ,  0.24531619,  0.12597807,  0.12873426,  0.14357343,\n",
       "        0.5214272 , -0.9172658 ,  0.5530365 , -0.74684995,  0.21388508,\n",
       "        1.0841601 , -0.23538832,  0.3047939 ,  0.14637445,  0.51675993,\n",
       "        0.51090246,  1.3562737 ,  1.8032838 ,  0.6021039 , -0.13209277,\n",
       "        0.68488777,  0.03495285,  0.8596143 ,  0.92250663, -0.7180531 ,\n",
       "        0.60217   , -0.5469921 ,  0.16337858, -0.5986445 ,  0.4041892 ,\n",
       "       -0.5659805 , -0.43969852,  0.48429614, -0.6750977 , -0.9770326 ,\n",
       "       -0.11523149, -0.8135256 ,  0.8823747 ,  1.3896174 , -0.1812314 ,\n",
       "       -0.00965889,  0.72365505,  0.1416582 ,  0.08070442,  0.5991289 ,\n",
       "       -0.45289192,  0.15261953,  1.3674932 , -1.1744913 , -0.44874692,\n",
       "        1.1256884 , -0.72741574,  0.05510331, -0.38129258,  0.47022706,\n",
       "        0.28324962,  0.97862387, -0.80632156, -0.13851686, -0.751     ,\n",
       "       -0.5995591 , -0.24834026, -1.4388578 , -0.14324796,  0.93846744,\n",
       "        1.5930433 , -0.02302027,  0.12475186,  0.19704862, -0.37015063,\n",
       "        0.07650711,  0.20219395,  0.6723446 , -1.7088258 ,  0.37222466,\n",
       "       -0.18425813, -0.31715867, -0.3409625 , -0.4073477 ,  0.26780528,\n",
       "       -0.42563525, -0.66635907, -1.424281  , -0.40527722,  0.95332724],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# как представлено слово Наташа\n",
    "w2v_vect[\"наташа\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alex/.local/lib/python3.6/site-packages/ipykernel_launcher.py:6: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "27    [-0.14450927, 0.07438644, 0.25057772, 0.001098...\n",
       "0     [-0.012421524, 0.007526146, 0.02644584, 0.0022...\n",
       "20                                                  NaN\n",
       "26    [-0.09343083, 0.05059665, 0.16415134, -0.00430...\n",
       "54    [-0.0617709, 0.013402337, 0.10507288, -0.00649...\n",
       "7                                                   NaN\n",
       "10    [-0.012421524, 0.007526146, 0.02644584, 0.0022...\n",
       "14    [-0.29240718, 0.050909456, 0.42542592, -0.0369...\n",
       "57    [-0.37809783, -0.012650042, 0.49503136, -0.076...\n",
       "29    [-0.02670082, 0.022555731, 0.056794405, -0.000...\n",
       "18    [-0.2501593, 0.05255475, 0.37357274, -0.025573...\n",
       "13    [-0.93176603, -0.42990717, 0.9347478, -0.32908...\n",
       "51    [-0.06518073, 0.03434562, 0.11545077, 0.000774...\n",
       "5     [-0.2732223, 0.04063116, 0.40220943, -0.034149...\n",
       "2     [-0.1505694, 0.13543874, 0.30505425, 0.0174698...\n",
       "53    [-0.027555766, 0.23452178, 0.22015241, 0.08266...\n",
       "11    [-0.16647264, 0.12476157, 0.31941226, 0.002111...\n",
       "15    [-0.010279304, 0.007055841, 0.02412204, 0.0002...\n",
       "32    [-0.44932574, -0.07640743, 0.54601413, -0.1107...\n",
       "22    [-0.11619426, 0.082777046, 0.21007161, 0.00713...\n",
       "49    [-0.039328575, 0.014524252, 0.06250489, -0.007...\n",
       "52    [-0.21491294, 0.049696986, 0.31796905, -0.0205...\n",
       "38    [-0.45062914, -0.10229705, 0.53625023, -0.1281...\n",
       "16    [-0.15654844, 0.1398996, 0.31741324, 0.0250857...\n",
       "55    [-0.19276623, 0.04103514, 0.29046127, -0.02867...\n",
       "48    [-0.06169694, 0.22268184, 0.25204474, 0.078009...\n",
       "1     [-0.16647264, 0.12476157, 0.31941226, 0.002111...\n",
       "56    [-0.13915044, 0.03297649, 0.20461673, -0.01828...\n",
       "47    [-0.1344265, 0.16896352, 0.2877777, 0.0168025,...\n",
       "41    [-0.43014377, -0.06456998, 0.5133884, -0.09303...\n",
       "8     [-0.1505694, 0.13543874, 0.30505425, 0.0174698...\n",
       "43    [-0.05751533, 0.022265717, 0.0862468, 0.000731...\n",
       "44    [-0.088569105, 0.17941344, 0.2516284, 0.061997...\n",
       "6     [-0.21199875, 0.072828755, 0.34126297, -0.0098...\n",
       "30    [-0.061434284, 0.018471885, 0.09376129, -0.004...\n",
       "50                                                  NaN\n",
       "28    [-0.04784795, 0.049965497, 0.10599399, 0.00235...\n",
       "31    [-0.3577876, 0.007905283, 0.4900392, -0.069602...\n",
       "42    [-0.13615286, 0.16183928, 0.29389215, 0.024856...\n",
       "58    [-0.2095867, 0.08725339, 0.34918603, -0.010447...\n",
       "21    [-0.42353827, -0.054685708, 0.533793, -0.09969...\n",
       "36    [-0.027553944, 0.008559933, 0.037212025, -0.00...\n",
       "45    [-0.2732223, 0.04063116, 0.40220943, -0.034149...\n",
       "33    [0.044443425, 0.28298143, 0.14797339, 0.131081...\n",
       "46    [-0.42353827, -0.054685708, 0.533793, -0.09969...\n",
       "17    [-0.04185939, 0.0062709604, 0.061958652, -0.00...\n",
       "23    [-0.031169385, 0.030702436, 0.072380766, 0.004...\n",
       "37                                                  NaN\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# усредним векторы слов\n",
    "def text2vec(text):\n",
    "    vecs = []\n",
    "    for word in text:\n",
    "        try:\n",
    "            vecs.append(w2v_vect[word])\n",
    "        except KeyError:\n",
    "            pass\n",
    "        return np.sum(vecs, axis=0) / len(vecs)\n",
    "\n",
    "    \n",
    "    \n",
    "w2v_train = X_train_w2v.apply(text2vec)\n",
    "w2v_test = X_test_w2v.apply(text2vec)\n",
    "\n",
    "w2v_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# w2v_train = w2v_train.drop([w2v_train.index[14] , w2v_train.index[14]])\n",
    "# w2v_train = w2v_train.drop([w2v_train.index[34] , w2v_train.index[34]])\n",
    "# w2v_train = w2v_train.drop([w2v_train.index[35] , w2v_train.index[35]])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#w2v_train = np.dstack(w2v_train)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27    [-0.14450927, 0.07438644, 0.25057772, 0.001098...\n",
       "0     [-0.012421524, 0.007526146, 0.02644584, 0.0022...\n",
       "20                                                  NaN\n",
       "26    [-0.09343083, 0.05059665, 0.16415134, -0.00430...\n",
       "54    [-0.0617709, 0.013402337, 0.10507288, -0.00649...\n",
       "7                                                   NaN\n",
       "10    [-0.012421524, 0.007526146, 0.02644584, 0.0022...\n",
       "14    [-0.29240718, 0.050909456, 0.42542592, -0.0369...\n",
       "57    [-0.37809783, -0.012650042, 0.49503136, -0.076...\n",
       "29    [-0.02670082, 0.022555731, 0.056794405, -0.000...\n",
       "18    [-0.2501593, 0.05255475, 0.37357274, -0.025573...\n",
       "13    [-0.93176603, -0.42990717, 0.9347478, -0.32908...\n",
       "51    [-0.06518073, 0.03434562, 0.11545077, 0.000774...\n",
       "5     [-0.2732223, 0.04063116, 0.40220943, -0.034149...\n",
       "2     [-0.1505694, 0.13543874, 0.30505425, 0.0174698...\n",
       "53    [-0.027555766, 0.23452178, 0.22015241, 0.08266...\n",
       "11    [-0.16647264, 0.12476157, 0.31941226, 0.002111...\n",
       "15    [-0.010279304, 0.007055841, 0.02412204, 0.0002...\n",
       "32    [-0.44932574, -0.07640743, 0.54601413, -0.1107...\n",
       "22    [-0.11619426, 0.082777046, 0.21007161, 0.00713...\n",
       "49    [-0.039328575, 0.014524252, 0.06250489, -0.007...\n",
       "52    [-0.21491294, 0.049696986, 0.31796905, -0.0205...\n",
       "38    [-0.45062914, -0.10229705, 0.53625023, -0.1281...\n",
       "16    [-0.15654844, 0.1398996, 0.31741324, 0.0250857...\n",
       "55    [-0.19276623, 0.04103514, 0.29046127, -0.02867...\n",
       "48    [-0.06169694, 0.22268184, 0.25204474, 0.078009...\n",
       "1     [-0.16647264, 0.12476157, 0.31941226, 0.002111...\n",
       "56    [-0.13915044, 0.03297649, 0.20461673, -0.01828...\n",
       "47    [-0.1344265, 0.16896352, 0.2877777, 0.0168025,...\n",
       "41    [-0.43014377, -0.06456998, 0.5133884, -0.09303...\n",
       "8     [-0.1505694, 0.13543874, 0.30505425, 0.0174698...\n",
       "43    [-0.05751533, 0.022265717, 0.0862468, 0.000731...\n",
       "44    [-0.088569105, 0.17941344, 0.2516284, 0.061997...\n",
       "6     [-0.21199875, 0.072828755, 0.34126297, -0.0098...\n",
       "30    [-0.061434284, 0.018471885, 0.09376129, -0.004...\n",
       "50                                                  NaN\n",
       "28    [-0.04784795, 0.049965497, 0.10599399, 0.00235...\n",
       "31    [-0.3577876, 0.007905283, 0.4900392, -0.069602...\n",
       "42    [-0.13615286, 0.16183928, 0.29389215, 0.024856...\n",
       "58    [-0.2095867, 0.08725339, 0.34918603, -0.010447...\n",
       "21    [-0.42353827, -0.054685708, 0.533793, -0.09969...\n",
       "36    [-0.027553944, 0.008559933, 0.037212025, -0.00...\n",
       "45    [-0.2732223, 0.04063116, 0.40220943, -0.034149...\n",
       "33    [0.044443425, 0.28298143, 0.14797339, 0.131081...\n",
       "46    [-0.42353827, -0.054685708, 0.533793, -0.09969...\n",
       "17    [-0.04185939, 0.0062709604, 0.061958652, -0.00...\n",
       "23    [-0.031169385, 0.030702436, 0.072380766, 0.004...\n",
       "37                                                  NaN\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Классификация текстов\n",
    "Для каждого эмбеддинга вычислим по два суммарных вектора - для текстов истории и мира(вона и мир)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 23015)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mir_mean_bof = np.sum( bof_train[y_train == 0], axis=0 )\n",
    "mir_mean_bof.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "istoria_mean_bof = np.sum( bof_train[y_train == 1], axis=0 )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Для TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 23015)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mir_mean_tfidf = np.sum(tfidf_train[y_train == 0], axis=0 )\n",
    "\n",
    "istoria_mean_tfidf = np.sum(tfidf_train[y_train == 1], axis=0 )\n",
    "\n",
    "\n",
    "mir_mean_tfidf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Для Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# mir_mean_w2v = np.sum(w2v_train[:,y_train==0], axis=0)\n",
    "\n",
    "# istoria_mean_w2v = np.sum(w2v_train[:,y_train==1], axis=0)\n",
    "\n",
    "# mir_mean_w2v.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mir_mean_w2v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Построим датафреймы с результатами классификаций тестовых текстов. Решение - по косинусному расстоянию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mir</th>\n",
       "      <th>istoria</th>\n",
       "      <th>predict</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.018832</td>\n",
       "      <td>0.190968</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.013855</td>\n",
       "      <td>0.190964</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.015256</td>\n",
       "      <td>0.217468</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.218037</td>\n",
       "      <td>0.038851</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.015418</td>\n",
       "      <td>0.199935</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.018033</td>\n",
       "      <td>0.184858</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.216267</td>\n",
       "      <td>0.036906</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.232957</td>\n",
       "      <td>0.037328</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.226318</td>\n",
       "      <td>0.041814</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.016145</td>\n",
       "      <td>0.203064</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.018627</td>\n",
       "      <td>0.222055</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.197240</td>\n",
       "      <td>0.035911</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         mir   istoria  predict  class\n",
       "0   0.018832  0.190968      1.0    0.0\n",
       "1   0.013855  0.190964      1.0    0.0\n",
       "2   0.015256  0.217468      1.0    0.0\n",
       "3   0.218037  0.038851      0.0    1.0\n",
       "4   0.015418  0.199935      1.0    0.0\n",
       "5   0.018033  0.184858      1.0    0.0\n",
       "6   0.216267  0.036906      0.0    1.0\n",
       "7   0.232957  0.037328      0.0    1.0\n",
       "8   0.226318  0.041814      0.0    1.0\n",
       "9   0.016145  0.203064      1.0    0.0\n",
       "10  0.018627  0.222055      1.0    0.0\n",
       "11  0.197240  0.035911      0.0    1.0"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "bof_mir = np.apply_along_axis(cosine, 1, bof_test.toarray(), v=mir_mean_bof)\n",
    "bof_istoria = np.apply_along_axis(cosine, 1, bof_test.toarray(), v=istoria_mean_bof)\n",
    "\n",
    "bof_results = pd.DataFrame ([\n",
    "    bof_mir,\n",
    "    bof_istoria,\n",
    "    np.maximum(bof_mir, bof_istoria) == bof_istoria,\n",
    "    y_test\n",
    "], index=[\"mir\", \"istoria\", \"predict\", \"class\"]).T.astype(np.float)\n",
    "\n",
    "bof_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy_score(bof_results[\"predict\"], bof_results[\"class\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mir</th>\n",
       "      <th>istoria</th>\n",
       "      <th>predict</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.049734</td>\n",
       "      <td>0.288472</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.045266</td>\n",
       "      <td>0.284744</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.046519</td>\n",
       "      <td>0.303924</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.347278</td>\n",
       "      <td>0.128319</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.046963</td>\n",
       "      <td>0.293790</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.050565</td>\n",
       "      <td>0.282672</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.345179</td>\n",
       "      <td>0.124254</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.358096</td>\n",
       "      <td>0.123501</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.352732</td>\n",
       "      <td>0.126258</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.048311</td>\n",
       "      <td>0.295477</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.049502</td>\n",
       "      <td>0.310571</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.326369</td>\n",
       "      <td>0.120191</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         mir   istoria  predict  class\n",
       "0   0.049734  0.288472      1.0    0.0\n",
       "1   0.045266  0.284744      1.0    0.0\n",
       "2   0.046519  0.303924      1.0    0.0\n",
       "3   0.347278  0.128319      0.0    1.0\n",
       "4   0.046963  0.293790      1.0    0.0\n",
       "5   0.050565  0.282672      1.0    0.0\n",
       "6   0.345179  0.124254      0.0    1.0\n",
       "7   0.358096  0.123501      0.0    1.0\n",
       "8   0.352732  0.126258      0.0    1.0\n",
       "9   0.048311  0.295477      1.0    0.0\n",
       "10  0.049502  0.310571      1.0    0.0\n",
       "11  0.326369  0.120191      0.0    1.0"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_mir = np.apply_along_axis(cosine, 1, tfidf_test.toarray(), v=mir_mean_tfidf)\n",
    "tfidf_istoria = np.apply_along_axis(cosine, 1, tfidf_test.toarray(), v=istoria_mean_tfidf)\n",
    "\n",
    "tfidf_results = pd.DataFrame ([\n",
    "    tfidf_mir,\n",
    "    tfidf_istoria,\n",
    "    np.maximum(tfidf_mir, tfidf_istoria) == tfidf_istoria,\n",
    "    y_test\n",
    "], index=[\"mir\", \"istoria\", \"predict\", \"class\"]).T.astype (np.float)\n",
    "\n",
    "tfidf_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(tfidf_results[\"predict\"], tfidf_results[\"class\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# w2v не работает"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Попробуем применить классическую модель поверх эмбеддингов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "RandomForestClassifier().fit(tfidf_train.toarray(), y_train.tolist()).score(tfidf_test.toarray(), y_test.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RandomForestClassifier().fit(bof_train.toarray(), y_train.tolist()).score(bof_test.toarray(), y_test.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
