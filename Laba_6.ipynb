{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Лабораторная работа 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задачи:\n",
    "\n",
    "* Провести классификацию русских текстов на несколько категорий. Лучше большой текст\n",
    "* Провести предобработку текстов: нормализацию, лемматизацию и тд\n",
    "* Сравнить эмбеддинги\n",
    "* Попробовать несколько методов классификации (+косинусы)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Будем использовать Войну и мир, Краткую историю всего"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# будем делить Войду и мир, Краткую историю всего на partsCount одинаковых частей\n",
    "partsCount = 400\n",
    "myTestSize = 0.2\n",
    "\n",
    "textDir = \"/home/alex/Downloads/bmstuML/texts/\"\n",
    "\n",
    "warFile = textDir + \"voina_i_mir.txt\"\n",
    "\n",
    "istoriaFile = textDir + \"kratkaya.txt\"\n",
    "\n",
    "\n",
    "with open(warFile, encoding=\"utf8\") as f:\n",
    "    war_text = f.read()\n",
    "    \n",
    "with open(istoriaFile, encoding=\"utf8\") as f:\n",
    "    istoria_text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nЛев Толстой\\n\\nВойна и мир\\n\\nТома первый и второй\\n\\n\\n\\nВ.\\xa0Шкловский «Война и мир» Льва Толстого\\n\\n\\nЗамысел\\n\\nВ 1855 году появилось объявление об издании «Полярной звезды». На обложке книги в круге восходящего солнца были изображены пять портретов казненных декабристов; под портретами топор и подписано: «'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "war_text[:300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n«Краткая история почти всего на свете» Билла Брайсона — самая необычная энциклопедия из всех существующих! И это первая книга, которой была присуждена престижная европейская премия за вклад в развитие мировой науки имени Рене Декарта.\\n\\n\\n\\nСейчас, в начале 2003 года, я держу перед собой несколько стр'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "istoria_text[:300]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Токенизация\n",
    "\n",
    "Выделим из текстов отдельные слова. Удалим ненужные \"слова\" (знаки препинания, лишние символы)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/alex/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Лев',\n",
       " 'Толстой',\n",
       " 'Война',\n",
       " 'и',\n",
       " 'мир',\n",
       " 'Тома',\n",
       " 'первый',\n",
       " 'и',\n",
       " 'второй',\n",
       " 'В.',\n",
       " 'Шкловский',\n",
       " '«',\n",
       " 'Война',\n",
       " 'и',\n",
       " 'мир']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "nltk.download(\"punkt\")\n",
    "war_tokens = nltk.word_tokenize(war_text)\n",
    "\n",
    "war_tokens[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['«',\n",
       " 'Краткая',\n",
       " 'история',\n",
       " 'почти',\n",
       " 'всего',\n",
       " 'на',\n",
       " 'свете',\n",
       " '»',\n",
       " 'Билла',\n",
       " 'Брайсона',\n",
       " '—',\n",
       " 'самая',\n",
       " 'необычная',\n",
       " 'энциклопедия',\n",
       " 'из']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# второй текст\n",
    "istoria_tokens = nltk.word_tokenize(istoria_text)\n",
    "\n",
    "istoria_tokens[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['лев', 'толст', 'войн', 'и', 'мир', 'том', 'перв', 'и', 'втор', 'в.']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from snowballstemmer import RussianStemmer\n",
    "stemmer = RussianStemmer()\n",
    "stemmerResult = stemmer.stemWords(war_text.lower().split())\n",
    "\n",
    "stemmerResult[:10]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видим, слова получились \"кривыми\", простое обрезание окончания - не вариант. Воспользуемся лемматизатором."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymystem3\n",
    "\n",
    "mystem = pymystem3.Mystem()\n",
    "\n",
    "war_lemm = mystem.lemmatize(\" \".join(war_tokens))\n",
    "\n",
    "istoria_lemm = mystem.lemmatize(\" \".join(istoria_tokens))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['лев', ' ', 'толстой', ' ', 'война', ' ', 'и', ' ', 'мир', ' ']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "war_lemm[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['« ', 'краткий', ' ', 'история', ' ', 'почти', ' ', 'все', ' ', 'на']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "istoria_lemm[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на морфологический анализ слов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parse(word='свет', tag=OpencorporaTag('NOUN,inan,masc,Sgtm sing,nomn'), normal_form='свет', score=0.51923, methods_stack=((DictionaryAnalyzer(), 'свет', 557, 0),)),\n",
       " Parse(word='свет', tag=OpencorporaTag('NOUN,inan,masc,Sgtm sing,accs'), normal_form='свет', score=0.423076, methods_stack=((DictionaryAnalyzer(), 'свет', 557, 4),)),\n",
       " Parse(word='свет', tag=OpencorporaTag('NOUN,anim,femn,Name plur,gent'), normal_form='света', score=0.01923, methods_stack=((DictionaryAnalyzer(), 'свет', 237, 8),)),\n",
       " Parse(word='свет', tag=OpencorporaTag('NOUN,anim,femn,Name plur,accs'), normal_form='света', score=0.01923, methods_stack=((DictionaryAnalyzer(), 'свет', 237, 10),)),\n",
       " Parse(word='свет', tag=OpencorporaTag('NOUN,anim,femn,Name sing,voct,Infr'), normal_form='света', score=0.01923, methods_stack=((DictionaryAnalyzer(), 'свет', 237, 13),))]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pymorphy2\n",
    "morph = pymorphy2.MorphAnalyzer()\n",
    "morph.parse(\"свет\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Удалим знаки, пустые слова, числа\n",
    "\n",
    "bad_chars = [\"«\", \"»\",\".\",\",\",\"—\",\":\",\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\",\"0\",\"?\",\"-\",\"[\",\"]\", \"стр\", \"(\", \")\",\n",
    "            \";\", \"X\", \"!\", \"издание\", \"…\", \"’\",\"&\"]\n",
    "\n",
    "def containsStr(a,b):\n",
    "    for i in b:\n",
    "        if i in a:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def deleteWords(wordList):\n",
    "    resultList = [item for item in wordList if len(item) > 1 ]\n",
    "    resultList = [item for item in resultList if not containsStr(item, bad_chars) ]\n",
    "    return resultList\n",
    "\n",
    "\n",
    "\n",
    "war_lemm_clear = deleteWords(war_lemm)\n",
    "\n",
    "istoria_lemm_clear = deleteWords(istoria_lemm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['лев',\n",
       " 'толстой',\n",
       " 'война',\n",
       " 'мир',\n",
       " 'том',\n",
       " 'первый',\n",
       " 'второй',\n",
       " 'шкловский',\n",
       " 'война',\n",
       " 'мир']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "war_lemm_clear[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['краткий',\n",
       " 'история',\n",
       " 'почти',\n",
       " 'все',\n",
       " 'на',\n",
       " 'свет',\n",
       " 'билл',\n",
       " 'брайсон',\n",
       " 'самый',\n",
       " 'необычный']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "istoria_lemm_clear[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "war_text_clear = \" \".join(war_lemm_clear)\n",
    "istoria_text_clear = \" \".join(istoria_lemm_clear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'лев толстой война мир том первый второй шкловский война мир лев толстой замысел год появляться объявление об полярный звезда на обложка книга круг восходить солнце быть изображать пять портрет казнить декабрист под портрет топор подписывать июль год том помечать день казнь декабрист над заглавие туч'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "war_text_clear[:300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# сохраним текста\n",
    "\n",
    "# with open(textDir+ '1.txt', 'w') as file:\n",
    "#     file.write(war_text_clear)\n",
    "    \n",
    "# with open(textDir+ '2.txt', 'w') as file:\n",
    "#     file.write(istoria_text_clear)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# функция разделения на части\n",
    "def chunkify(lst,n):\n",
    "    return [lst[i::n] for i in range(n)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from string import punctuation\n",
    "\n",
    "# def lemmatize(input_text):\n",
    "#     tokens = nltk.word_tokenize(input_text)\n",
    "#     normed_tokens = [morph.parse(s)[0].normal_form for s in tokens]\n",
    "#     # исключии стоп слова\n",
    "#     normed_tokens = deleteWords(normed_tokens)\n",
    "#     return ' '.join(normed_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# # nogroToByM uycTow naTtadpevim\n",
    "# df = pd.DataFrame(columns=['text', 'class'])\n",
    "\n",
    "# dir0 = textDir + \"/0\"\n",
    "# dir1 = textDir + \"/1\"\n",
    "\n",
    "# for filename in os.listdir(dir0) :\n",
    "#     with open(os.path.join(dir0, filename), encoding='utf8') as file:\n",
    "#         contents = lemmatize(file.read())\n",
    "\n",
    "#     df = df.append(pd.Series({'text': contents, 'class': 0}), ignore_index=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# for filename in os.listdir(dir1) :\n",
    "#     with open(os.path.join(dir1, filename), encoding='utf8') as file:\n",
    "#         contents = lemmatize(file.read())\n",
    "\n",
    "#     df = df.append(pd.Series({'text': contents, 'class': 1}), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['история',\n",
       " 'флэннерить',\n",
       " 'точно',\n",
       " 'яйцо',\n",
       " 'же',\n",
       " 'помогать',\n",
       " 'содержать',\n",
       " 'как',\n",
       " 'шестидесятый',\n",
       " 'ускоритель']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "war_parts = chunkify(war_lemm_clear, partsCount)\n",
    "istoria_parts = chunkify(istoria_lemm_clear, partsCount)\n",
    "\n",
    "istoria_parts[1][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# объединяем слова в частях\n",
    "# на выходе - список из текстов\n",
    "def joinWordsToTextList(wordsLists):\n",
    "    result = []\n",
    "    for i in wordsLists:\n",
    "        oneText = \" \".join(i)\n",
    "        result.append(oneText)\n",
    "    return result\n",
    "\n",
    "\n",
    "war_texts = joinWordsToTextList(war_parts)\n",
    "istoria_texts = joinWordsToTextList(istoria_parts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# war_texts[1][:300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "war_texts size:3496 \tistoria_text size:2585\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(columns=[\"text\",\"class\"])\n",
    "\n",
    "\n",
    "for i in war_texts:\n",
    "    df = df.append(pd.Series({\"text\":i, \"class\":0}), ignore_index=True)\n",
    "\n",
    "# у второго типа текстов класс == 1\n",
    "for i in istoria_texts:\n",
    "    df = df.append(pd.Series({\"text\":i, \"class\":1}), ignore_index=True)\n",
    "    \n",
    "\n",
    "print(\"war_texts size:\"+str(len(war_texts[3])), \"\\tistoria_text size:\"+str(len(istoria_texts[3])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>лев приобретать понимать состоять под как нет ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>толстой он сила только влияние бы мать борьба ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>война великий народ то исторический смерть тол...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>мир слава слабость что событие она конец помощ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>том который декабрист мы война новый давать не...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>795</th>\n",
       "      <td>рич куча отращивать добела предполагать малень...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>796</th>\n",
       "      <td>из создавать плавник шар что что склоняться от...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797</th>\n",
       "      <td>музей живой конечность из мочь крошечный велич...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>798</th>\n",
       "      <td>штат существо щеголять железо сам точка млрд б...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799</th>\n",
       "      <td>виктория на крыло никель этот над год обнаружи...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>800 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text class\n",
       "0    лев приобретать понимать состоять под как нет ...     0\n",
       "1    толстой он сила только влияние бы мать борьба ...     0\n",
       "2    война великий народ то исторический смерть тол...     0\n",
       "3    мир слава слабость что событие она конец помощ...     0\n",
       "4    том который декабрист мы война новый давать не...     0\n",
       "..                                                 ...   ...\n",
       "795  рич куча отращивать добела предполагать малень...     1\n",
       "796  из создавать плавник шар что что склоняться от...     1\n",
       "797  музей живой конечность из мочь крошечный велич...     1\n",
       "798  штат существо щеголять железо сам точка млрд б...     1\n",
       "799  виктория на крыло никель этот над год обнаружи...     1\n",
       "\n",
       "[800 rows x 2 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# разбив на трейн и тест\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df[\"text\"], df[\"class\"], test_size=myTestSize, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "264    хотеть год роман отражение андрей тот один сил...\n",
       "615    естественный небольшой век этот все размышлени...\n",
       "329    стиль быть история осуществляться взятка котор...\n",
       "342    восторг причем думать выражать как становиться...\n",
       "394    севастополь пьер не не пьер хотеть портфель ко...\n",
       "                             ...                        \n",
       "71     свой николай эпоха все герой любовь роман умол...\n",
       "106    весь наташа уже описывать выглядеть роман суд ...\n",
       "270    так больший что положение гореть чтобы последо...\n",
       "435    перед зеландия другой эволюция что неприятно и...\n",
       "102    полярный это этот мир четкость конфликт жизнь ...\n",
       "Name: text, Length: 640, dtype: object"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "696    национальный быть что просто самый знание прав...\n",
       "667    штат что курьезность послужить область уйма об...\n",
       "63     как для наполеоновский бы во роман оливер скор...\n",
       "533    этот мочь наполняться вознаграждать содержать ...\n",
       "66     свой пьер нестарый отсутствие счастие реалисти...\n",
       "                             ...                        \n",
       "589    лондон действие тот сочетание часть находиться...\n",
       "798    штат существо щеголять железо сам точка млрд б...\n",
       "744    даллас или из собственный что направление мате...\n",
       "513    здесь поздравлять атом все здоровый мой столь ...\n",
       "670    оффенбур приниматься что он оставаться вопрос ...\n",
       "Name: text, Length: 160, dtype: object"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag-of-Words-эмбеддинг\n",
    "на всех данных обучние - чтоб все слова были учтены?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "bof_vect = CountVectorizer()\n",
    "bof_vect.fit(np.hstack([X_train, X_test]))\n",
    "bof_train = bof_vect.transform(X_train)\n",
    "bof_test = bof_vect.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 1, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# пространство признаков\n",
    "\n",
    "bof_train.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(640, 23015)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bof_train.toarray().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF-Эмбеддинг"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vect = TfidfVectorizer()\n",
    "tfidf_vect.fit(np.hstack([X_train, X_test]))\n",
    "tfidf_train = tfidf_vect.transform(X_train)\n",
    "tfidf_test = tfidf_vect.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.05868196, 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_train.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(640, 23015)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_train.toarray().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2vec-эмбеддинг\n",
    "Немного другой формат данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "X_train_w2v = X_train.apply(str.split)\n",
    "X_test_w2v = X_test.apply(str.split)\n",
    "w2v_vect = Word2Vec(np.hstack([X_train_w2v, X_test_w2v]), size=160, min_count=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "264    [хотеть, год, роман, отражение, андрей, тот, о...\n",
       "615    [естественный, небольшой, век, этот, все, разм...\n",
       "329    [стиль, быть, история, осуществляться, взятка,...\n",
       "342    [восторг, причем, думать, выражать, как, стано...\n",
       "394    [севастополь, пьер, не, не, пьер, хотеть, порт...\n",
       "                             ...                        \n",
       "71     [свой, николай, эпоха, все, герой, любовь, ром...\n",
       "106    [весь, наташа, уже, описывать, выглядеть, рома...\n",
       "270    [так, больший, что, положение, гореть, чтобы, ...\n",
       "435    [перед, зеландия, другой, эволюция, что, непри...\n",
       "102    [полярный, это, этот, мир, четкость, конфликт,...\n",
       "Name: text, Length: 640, dtype: object"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_w2v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alex/.local/lib/python3.6/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('земля', 0.9965345859527588),\n",
       " ('если', 0.9844806790351868),\n",
       " ('вид', 0.9637594223022461),\n",
       " ('мы', 0.9588470458984375),\n",
       " ('более', 0.9585084915161133),\n",
       " ('почти', 0.9536319971084595),\n",
       " ('самый', 0.9487262964248657),\n",
       " ('существо', 0.9473338723182678),\n",
       " ('даже', 0.9460662603378296),\n",
       " ('теория', 0.9353926181793213)]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_vect.most_similar(positive=\"год\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alex/.local/lib/python3.6/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('князь', 0.1362890601158142),\n",
       " ('ты', 0.13006210327148438),\n",
       " ('наташа', 0.12526768445968628),\n",
       " ('пьер', 0.12225104868412018),\n",
       " ('сказать', 0.11963337659835815),\n",
       " ('андрей', 0.07721569389104843),\n",
       " ('лицо', 0.06798352301120758),\n",
       " ('ростов', 0.06383147090673447),\n",
       " ('она', 0.038992077112197876),\n",
       " ('да', 0.033359773457050323)]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_vect.most_similar(negative=[\"существо\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alex/.local/lib/python3.6/site-packages/ipykernel_launcher.py:2: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-2.94823050e-01,  2.34902352e-01,  1.55353872e-02,  5.65707088e-01,\n",
       "       -2.38489166e-01, -2.75986701e-01, -2.88902745e-02, -7.14717060e-02,\n",
       "        6.77703381e-01,  2.78774463e-02,  2.15267301e-01,  3.32254797e-01,\n",
       "        2.11352706e-01, -4.40875217e-02,  3.07136983e-01,  3.06816585e-02,\n",
       "        1.28426969e-01, -2.83240199e-01,  4.32906955e-01, -8.17743242e-01,\n",
       "       -6.81228042e-01,  4.30307627e-01,  2.20073387e-01, -5.52327394e-01,\n",
       "       -2.69692183e-01,  2.37412825e-01, -1.34634614e-01, -4.51808989e-01,\n",
       "        1.76651314e-01,  2.54281998e-01,  1.71549141e-01, -6.28879905e-01,\n",
       "       -4.23199117e-01,  2.15165064e-01,  7.59299323e-02, -2.52604727e-02,\n",
       "       -3.77696119e-02, -7.06914425e-01,  7.25381315e-01, -5.20020239e-02,\n",
       "        1.88641295e-01, -2.94054478e-01, -1.09110475e-02,  1.45482093e-01,\n",
       "       -1.06977308e+00,  3.84849906e-02, -5.35340756e-02, -1.08878374e+00,\n",
       "        9.58952159e-02,  3.37399483e-01, -1.87360674e-01, -4.88749772e-01,\n",
       "        1.68457121e-01, -1.42433569e-01,  3.94135535e-01, -9.68159661e-02,\n",
       "        2.16481373e-01,  6.06834352e-01, -1.50137976e-01, -1.00110866e-01,\n",
       "        2.78840899e-01,  1.83323503e-01, -2.82843471e-01, -1.95522666e-01,\n",
       "       -1.43272445e-01,  2.57137984e-01, -2.97692150e-01, -2.23244369e-01,\n",
       "        6.63732588e-02,  1.58155531e-01,  7.96094358e-01,  5.97966671e-01,\n",
       "       -8.51078928e-02,  1.91697124e-02, -3.98717165e-01,  7.80582309e-01,\n",
       "       -3.08590382e-01, -2.09485233e-01,  2.93276589e-02,  8.61385226e-01,\n",
       "       -2.24252135e-01,  1.12409495e-01, -4.07956660e-01, -2.45216582e-02,\n",
       "       -1.78686127e-01,  2.32205957e-01,  3.02840948e-01, -1.41696587e-01,\n",
       "        5.13428211e-01, -3.66772115e-01, -4.72221792e-01, -3.41114625e-02,\n",
       "        2.48448730e-01,  1.10619724e-01,  2.10230857e-01, -6.60521984e-02,\n",
       "       -1.46076262e-01,  9.24969256e-01, -1.85831934e-01,  3.75195146e-01,\n",
       "       -1.48745492e-01,  2.18879543e-02,  6.87308371e-01,  2.57904947e-01,\n",
       "       -4.44829971e-01, -7.45505393e-01,  5.74017949e-02, -1.73962593e-01,\n",
       "        9.82699096e-02, -1.40027165e-01, -3.15958075e-02, -4.95817482e-01,\n",
       "       -3.49668056e-01, -9.71791223e-02,  2.34464761e-02,  2.11349800e-01,\n",
       "       -1.49634033e-01,  5.50209820e-01, -8.71824086e-01, -3.85118991e-01,\n",
       "        8.69556097e-04, -1.06421515e-01, -2.81486005e-01, -8.83797929e-02,\n",
       "       -2.10588366e-01, -3.66520733e-01, -1.66304067e-01,  2.52270013e-01,\n",
       "       -3.78549367e-01,  1.72329232e-01,  6.80006295e-02, -1.11291480e+00,\n",
       "        3.35403979e-01,  1.01233089e+00, -7.28155792e-01, -7.61325538e-01,\n",
       "       -6.89581454e-01, -4.55750048e-01,  5.66510856e-01,  1.78333655e-01,\n",
       "        6.44777343e-02,  9.23892390e-03,  2.95847565e-01,  6.83547482e-02,\n",
       "        8.32396820e-02, -7.10232794e-01,  8.49684328e-02, -3.25506151e-01,\n",
       "       -3.63404639e-02,  1.45587415e-01, -5.78737915e-01,  8.47782314e-01,\n",
       "       -1.56655058e-01, -1.11424029e+00, -1.35060772e-01,  4.87483107e-02,\n",
       "        2.36528501e-01,  9.42928866e-02, -1.63774475e-01, -1.21475026e-01],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# как представлено слово земля\n",
    "w2v_vect[\"земля\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alex/.local/lib/python3.6/site-packages/ipykernel_launcher.py:6: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "264    [0.40148202, -0.13114636, 0.08417224, 0.093339...\n",
       "615    [0.1996644, -0.031440105, 0.062310632, 0.19608...\n",
       "329    [0.40392992, -0.13218908, 0.084841885, 0.09331...\n",
       "342    [0.43053618, -0.14531736, 0.08748263, 0.079589...\n",
       "394    [0.42451337, -0.14174514, 0.086844474, 0.08285...\n",
       "                             ...                        \n",
       "71     [0.4144408, -0.13631926, 0.08605696, 0.0918676...\n",
       "106    [0.40112707, -0.13162608, 0.083633736, 0.09032...\n",
       "270    [0.41912636, -0.13982041, 0.08575793, 0.082934...\n",
       "435    [0.20149308, -0.033317048, 0.061888132, 0.1915...\n",
       "102    [0.39735636, -0.1291441, 0.08374218, 0.0954770...\n",
       "Name: text, Length: 640, dtype: object"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# усредним векторы слов\n",
    "def text2vec(text):\n",
    "    vecs = []\n",
    "    for word in text:\n",
    "        try:\n",
    "            vecs.append(w2v_vect[word])\n",
    "        except KeyError:\n",
    "            pass\n",
    "    return np.sum(vecs, axis=0) / len(vecs)\n",
    "\n",
    "    \n",
    "    \n",
    "w2v_train = X_train_w2v.apply(text2vec)\n",
    "w2v_test = X_test_w2v.apply(text2vec)\n",
    "\n",
    "w2v_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_train = np.dstack(w2v_train)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.40148202,  0.1996644 ,  0.40392992, ...,  0.41912636,\n",
       "         0.20149308,  0.39735636],\n",
       "       [-0.13114636, -0.03144011, -0.13218908, ..., -0.13982041,\n",
       "        -0.03331705, -0.1291441 ],\n",
       "       [ 0.08417224,  0.06231063,  0.08484188, ...,  0.08575793,\n",
       "         0.06188813,  0.08374218],\n",
       "       ...,\n",
       "       [ 0.0959761 ,  0.08545016,  0.09635032, ...,  0.09662557,\n",
       "         0.08453091,  0.09551174],\n",
       "       [ 0.11246458,  0.03771376,  0.11333334, ...,  0.11910814,\n",
       "         0.0388655 ,  0.11088072],\n",
       "       [-0.28216082, -0.21835066, -0.28337517, ..., -0.28675652,\n",
       "        -0.21779577, -0.2811363 ]], dtype=float32)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(160, 640)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Классификация текстов\n",
    "Для каждого эмбеддинга вычислим по два суммарных вектора - для текстов истории и мира(вона и мир)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Для Bag-of-Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 23015)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# средний текст войны и мира\n",
    "mir_mean_bof = np.sum( bof_train[y_train == 0], axis=0 )\n",
    "mir_mean_bof.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 23015)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# средний текст истории\n",
    "istoria_mean_bof = np.sum( bof_train[y_train == 1], axis=0 )\n",
    "istoria_mean_bof.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Для TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 23015)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mir_mean_tfidf = np.sum(tfidf_train[y_train == 0], axis=0 )\n",
    "\n",
    "istoria_mean_tfidf = np.sum(tfidf_train[y_train == 1], axis=0 )\n",
    "\n",
    "\n",
    "mir_mean_tfidf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Для Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(160,)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "mir_mean_w2v = np.sum(w2v_train[:,y_train==0], axis=1)\n",
    "\n",
    "istoria_mean_w2v = np.sum(w2v_train[:,y_train==1], axis=1)\n",
    "\n",
    "mir_mean_w2v.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 130.77219  ,  -43.02624  ,   27.191893 ,   28.78016  ,\n",
       "        105.58279  ,  -34.633293 ,  -38.023174 ,    7.979184 ,\n",
       "        -62.360767 ,  -64.91503  ,   12.221597 ,  -36.243176 ,\n",
       "        -32.004898 ,   13.283019 ,  146.64664  ,   24.513514 ,\n",
       "        -10.21763  ,    9.083516 ,   10.542308 ,   10.454503 ,\n",
       "        -15.301132 ,  -51.942078 ,   58.39855  ,  -47.762318 ,\n",
       "       -152.27715  ,   32.266457 ,   43.22663  ,  -48.80561  ,\n",
       "         77.453735 ,   84.463875 ,   -5.9783936,   74.45671  ,\n",
       "        -24.969944 ,  196.47798  ,   70.5737   ,   47.171608 ,\n",
       "        -30.887072 ,   53.099068 ,   30.80424  ,   89.85188  ,\n",
       "         31.40989  ,   43.275963 ,   31.276043 ,  -30.753492 ,\n",
       "          5.3987265,  160.50761  , -117.725784 ,  -66.904564 ,\n",
       "        -33.9499   ,  -24.136772 ,  -38.711174 ,   69.45814  ,\n",
       "         19.408567 ,  -36.036316 ,  -10.918736 ,  -87.85166  ,\n",
       "        -77.32976  ,  -47.549763 ,   14.765736 , -121.93524  ,\n",
       "         93.55587  ,  -51.77681  , -104.660576 ,  -24.388266 ,\n",
       "         59.44525  ,  -69.33928  ,  101.124695 ,  -68.00602  ,\n",
       "         77.65046  ,   20.806261 ,  154.42357  ,   28.865978 ,\n",
       "        -37.7994   ,   19.386238 ,   -9.780976 ,   38.20219  ,\n",
       "        -13.193366 ,  -11.112435 ,  -23.261719 ,  117.36914  ,\n",
       "         24.859585 ,  -53.654926 ,   58.716785 ,  -55.197292 ,\n",
       "         37.642075 ,   58.603294 ,  -62.810986 ,   -9.3526535,\n",
       "        115.92895  ,   34.849983 ,  -26.577583 ,  163.4056   ,\n",
       "         64.17272  ,  -13.5090065,   16.177338 ,  -81.55538  ,\n",
       "         87.85209  ,   10.454088 ,  105.84794  ,    9.307375 ,\n",
       "         13.36458  ,  -10.032982 ,   67.27032  ,  110.959694 ,\n",
       "       -122.14943  ,   42.759342 ,  -62.00872  ,  -37.939323 ,\n",
       "        -40.117523 ,   62.04862  ,  -30.298948 , -131.58374  ,\n",
       "        -14.53624  ,  -90.70469  ,  -44.812244 ,  -83.10671  ,\n",
       "         13.947946 ,   55.770157 ,  -17.934544 ,   18.413162 ,\n",
       "         11.270309 ,  -44.75897  , -176.12566  ,   75.49216  ,\n",
       "        -69.91824  ,  -70.36562  ,  -45.122147 ,   -2.9099014,\n",
       "         53.569427 ,  -53.52382  ,   33.18201  ,  -25.793821 ,\n",
       "        -39.693134 ,   92.26883  ,   18.908344 ,   37.174793 ,\n",
       "        -24.148947 ,  -21.131788 ,   14.776384 ,    1.3904283,\n",
       "        -14.187767 ,   14.364259 ,   -8.338528 ,  -18.575903 ,\n",
       "         -3.16872  ,  -29.868992 ,   31.311842 ,  -54.43429  ,\n",
       "        -21.707993 ,  -76.145386 ,  -35.90948  ,   77.83214  ,\n",
       "        -94.74306  ,  -77.84732  ,  -62.407467 ,   21.859793 ,\n",
       "        -31.572853 ,   30.859322 ,   36.87934  ,  -91.036316 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mir_mean_w2v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Построим датафреймы с результатами классификаций тестовых текстов. Решение - по косинусному расстоянию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mir</th>\n",
       "      <th>istoria</th>\n",
       "      <th>predict</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.482883</td>\n",
       "      <td>0.311288</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.429743</td>\n",
       "      <td>0.289305</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.198570</td>\n",
       "      <td>0.286129</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.426814</td>\n",
       "      <td>0.311105</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.153879</td>\n",
       "      <td>0.312206</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>0.486079</td>\n",
       "      <td>0.293769</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>0.330891</td>\n",
       "      <td>0.272752</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>0.447075</td>\n",
       "      <td>0.276866</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>0.447795</td>\n",
       "      <td>0.305260</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>0.473498</td>\n",
       "      <td>0.333679</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>160 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          mir   istoria  predict  class\n",
       "0    0.482883  0.311288      0.0    1.0\n",
       "1    0.429743  0.289305      0.0    1.0\n",
       "2    0.198570  0.286129      1.0    0.0\n",
       "3    0.426814  0.311105      0.0    1.0\n",
       "4    0.153879  0.312206      1.0    0.0\n",
       "..        ...       ...      ...    ...\n",
       "155  0.486079  0.293769      0.0    1.0\n",
       "156  0.330891  0.272752      0.0    1.0\n",
       "157  0.447075  0.276866      0.0    1.0\n",
       "158  0.447795  0.305260      0.0    1.0\n",
       "159  0.473498  0.333679      0.0    1.0\n",
       "\n",
       "[160 rows x 4 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "bof_mir = np.apply_along_axis(cosine, 1, bof_test.toarray(), v=mir_mean_bof)\n",
    "bof_istoria = np.apply_along_axis(cosine, 1, bof_test.toarray(), v=istoria_mean_bof)\n",
    "\n",
    "bof_results = pd.DataFrame ([\n",
    "    bof_mir,\n",
    "    bof_istoria,\n",
    "    np.maximum(bof_mir, bof_istoria) == bof_istoria,\n",
    "    y_test\n",
    "], index=[\"mir\", \"istoria\", \"predict\", \"class\"]).T.astype(np.float)\n",
    "\n",
    "bof_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy_score(bof_results[\"predict\"], bof_results[\"class\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mir</th>\n",
       "      <th>istoria</th>\n",
       "      <th>predict</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.801804</td>\n",
       "      <td>0.649217</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.772935</td>\n",
       "      <td>0.650867</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.503860</td>\n",
       "      <td>0.670587</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.781306</td>\n",
       "      <td>0.656577</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.488976</td>\n",
       "      <td>0.678448</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>0.790895</td>\n",
       "      <td>0.634754</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>0.726309</td>\n",
       "      <td>0.614806</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>0.782911</td>\n",
       "      <td>0.639474</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>0.784943</td>\n",
       "      <td>0.664064</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>0.785272</td>\n",
       "      <td>0.656781</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>160 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          mir   istoria  predict  class\n",
       "0    0.801804  0.649217      0.0    1.0\n",
       "1    0.772935  0.650867      0.0    1.0\n",
       "2    0.503860  0.670587      1.0    0.0\n",
       "3    0.781306  0.656577      0.0    1.0\n",
       "4    0.488976  0.678448      1.0    0.0\n",
       "..        ...       ...      ...    ...\n",
       "155  0.790895  0.634754      0.0    1.0\n",
       "156  0.726309  0.614806      0.0    1.0\n",
       "157  0.782911  0.639474      0.0    1.0\n",
       "158  0.784943  0.664064      0.0    1.0\n",
       "159  0.785272  0.656781      0.0    1.0\n",
       "\n",
       "[160 rows x 4 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_mir = np.apply_along_axis(cosine, 1, tfidf_test.toarray(), v=mir_mean_tfidf)\n",
    "tfidf_istoria = np.apply_along_axis(cosine, 1, tfidf_test.toarray(), v=istoria_mean_tfidf)\n",
    "\n",
    "tfidf_results = pd.DataFrame ([\n",
    "    tfidf_mir,\n",
    "    tfidf_istoria,\n",
    "    np.maximum(tfidf_mir, tfidf_istoria) == tfidf_istoria,\n",
    "    y_test\n",
    "], index=[\"mir\", \"istoria\", \"predict\", \"class\"]).T.astype (np.float)\n",
    "\n",
    "tfidf_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(tfidf_results[\"predict\"], tfidf_results[\"class\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mir</th>\n",
       "      <th>istoria</th>\n",
       "      <th>predict</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.801804</td>\n",
       "      <td>0.649217</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.772935</td>\n",
       "      <td>0.650867</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.503860</td>\n",
       "      <td>0.670587</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.781306</td>\n",
       "      <td>0.656577</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.488976</td>\n",
       "      <td>0.678448</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>0.790895</td>\n",
       "      <td>0.634754</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>0.726309</td>\n",
       "      <td>0.614806</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>0.782911</td>\n",
       "      <td>0.639474</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>0.784943</td>\n",
       "      <td>0.664064</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>0.785272</td>\n",
       "      <td>0.656781</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>160 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          mir   istoria  predict  class\n",
       "0    0.801804  0.649217      1.0    1.0\n",
       "1    0.772935  0.650867      0.0    1.0\n",
       "2    0.503860  0.670587      1.0    0.0\n",
       "3    0.781306  0.656577      1.0    1.0\n",
       "4    0.488976  0.678448      1.0    0.0\n",
       "..        ...       ...      ...    ...\n",
       "155  0.790895  0.634754      1.0    1.0\n",
       "156  0.726309  0.614806      0.0    1.0\n",
       "157  0.782911  0.639474      1.0    1.0\n",
       "158  0.784943  0.664064      1.0    1.0\n",
       "159  0.785272  0.656781      0.0    1.0\n",
       "\n",
       "[160 rows x 4 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# w2v\n",
    "\n",
    "w2v_mir = np.apply_along_axis(cosine, 0, w2v_test, v=mir_mean_w2v)\n",
    "w2v_istoria = np.apply_along_axis(cosine, 0, w2v_test, v=istoria_mean_w2v)\n",
    "\n",
    "w2v_results = pd.DataFrame ([\n",
    "    tfidf_mir,\n",
    "    tfidf_istoria,\n",
    "    np.maximum(w2v_mir, w2v_istoria) == w2v_istoria,\n",
    "    y_test\n",
    "], index=[\"mir\", \"istoria\", \"predict\", \"class\"]).T.astype (np.float)\n",
    "\n",
    "w2v_results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4625"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(w2v_results[\"predict\"], w2v_results[\"class\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Попробуем применить классическую модель поверх эмбеддингов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "RandomForestClassifier().fit(tfidf_train.toarray(), y_train.tolist()).score(tfidf_test.toarray(), y_test.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RandomForestClassifier().fit(bof_train.toarray(), y_train.tolist()).score(bof_test.toarray(), y_test.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
